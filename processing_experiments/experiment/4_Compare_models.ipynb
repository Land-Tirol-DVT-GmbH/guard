{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70e660b3",
   "metadata": {},
   "source": [
    "# Compares the models from the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb264c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiments_from_dir(directory):\n",
    "    experiments = {}\n",
    "    for file in Path(directory).glob(\"*.json\"):\n",
    "        with open(file, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "            # Extract model name from filename\n",
    "            filename = file.stem  # e.g., \"piiranha_flair_both_per_experiment\"\n",
    "            model_name = filename.split(\"_experiment\")[0]\n",
    "            experiments[model_name] = data\n",
    "    return experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3243ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrices(experiments):\n",
    "    num_models = len(experiments)\n",
    "    cols = 2\n",
    "    rows = (num_models + 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 5 * rows))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (model_name, data) in enumerate(experiments.items()):\n",
    "        cm = np.array(data['confusion_matrix'])\n",
    "        labels = data['labels']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=labels, yticklabels=labels,\n",
    "                    cmap=\"Blues\", ax=axes[i])\n",
    "        axes[i].set_title(f\"Confusion Matrix: {model_name}\")\n",
    "        axes[i].set_xlabel(\"Predicted\")\n",
    "        axes[i].set_ylabel(\"True\")\n",
    "\n",
    "    # Hide any unused subplots\n",
    "    for j in range(i + 1, len(axes)):\n",
    "        fig.delaxes(axes[j])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71267f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_entity_f2_scores(experiments):\n",
    "    entity_scores = []\n",
    "    beta = 2  # for F2 score\n",
    "    for model, data in experiments.items():\n",
    "        metrics = data[\"metrics\"]\n",
    "        for entity in [\"LOCATION\", \"AUT_LICENSE_PLATE\", \"PERSON\", \"PHONE_NUMBER\", \"EMAIL_ADDRESS\"]:\n",
    "            precision = metrics.get(f\"{entity}_precision\")\n",
    "            recall = metrics.get(f\"{entity}_recall\")\n",
    "            if precision is not None and recall is not None and (precision + recall) > 0:\n",
    "                f2 = (1 + beta**2) * (precision * recall) / ((beta**2 * precision) + recall)\n",
    "                entity_scores.append({\n",
    "                    \"Model\": model,\n",
    "                    \"Entity\": entity,\n",
    "                    \"F2 Score\": f2\n",
    "                })\n",
    "\n",
    "    df = pd.DataFrame(entity_scores)\n",
    "    df = df.sort_values(by=\"F2 Score\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(data=df, x=\"Entity\", y=\"F2 Score\", hue=\"Model\", dodge=True, order=df[\"Entity\"])\n",
    "    plt.title(\"Entity-Level F2 Scores (Recall-Focused)\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d3807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pii_f_scores(experiments):\n",
    "    # Extract and sort models by pii_f score\n",
    "    sorted_models = sorted(experiments.items(), key=lambda x: x[1]['metrics']['pii_f'], reverse=True)\n",
    "    model_names = [model for model, _ in sorted_models]\n",
    "    pii_f_scores = [data['metrics']['pii_f'] for _, data in sorted_models]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=model_names, y=pii_f_scores, palette=\"viridis\")\n",
    "    plt.ylabel(\"PII F2 Score\")\n",
    "    plt.xlabel(\"Model Name\")\n",
    "    plt.title(\"PII F2 Score per Model (Descending)\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1256d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = load_experiments_from_dir(\"results/dataset_april_11\")\n",
    "plot_confusion_matrices(experiments)\n",
    "plot_pii_f_scores(experiments)\n",
    "plot_entity_f2_scores(experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pj-software",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
